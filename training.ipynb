{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RTztf5hcXOmD",
        "KBMcW8ABegbn",
        "sh53SXOd8aHN",
        "doxWC4PKpfen"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoRosa3/Prova/blob/master/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdNFemPPVALK"
      },
      "source": [
        "# CONSEGNA GRUPPO 19\r\n",
        "*   Demetrio Trimarco\r\n",
        "*   Emilio Sorrentino\r\n",
        "*   Francesco Rosa\r\n",
        "*   Francesco Sabbarese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxM56tJtuNNm"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDvCOTaG6i1i"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPBrQQY_EWLM"
      },
      "source": [
        "## IMPORT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Etg11GmWz3q"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "from tensorflow import keras\r\n",
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from datetime import datetime\r\n",
        "from packaging import version\r\n",
        "import os\r\n",
        "import io\r\n",
        "from PIL import Image\r\n",
        "from functools import partial\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy\r\n",
        "import cv2\r\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUfutS_S3v02"
      },
      "source": [
        "# import functions for pre processing and data augmentation\r\n",
        "!cp /content/gdrive/MyDrive/CONSEGNA/TRAIN/corruptions.py .\r\n",
        "!cp /content/gdrive/MyDrive/CONSEGNA/TRAIN/augmentation_transforms.py .\r\n",
        "!cp /content/gdrive/MyDrive/CONSEGNA/TRAIN/dataset_tools.py .\r\n",
        "import dataset_tools\r\n",
        "!apt-get install libmagickwand-dev\r\n",
        "!pip install Wand\r\n",
        "import corruptions\r\n",
        "import augmentation_transforms\r\n",
        "\r\n",
        "# import vggface models\r\n",
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\r\n",
        "!pip install keras_vggface\r\n",
        "!pip install keras_applications\r\n",
        "from keras_vggface.vggface import VGGFace\r\n",
        "import keras_vggface.utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5LVA86NXLCH"
      },
      "source": [
        "## VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcwHkgAXEaPW"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/CONSEGNA/\"\n",
        "DIRECTORY_TRAIN = \"TRAIN/\"\n",
        "FOLDER_CHECKPOINT = BASE_PATH + DIRECTORY_TRAIN + \"MODELS/model.{epoch:02d}- {val_loss:.2f}.h5\"\n",
        "TENSOR_BOARD_PATH = BASE_PATH + DIRECTORY_TRAIN + \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "NUM_EPOCHS = 50\n",
        "BASE_MODEL = \"resnet50\"\n",
        "WEIGHTS = \"vggface\"\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_SIZE = 435000\n",
        "VAL_SIZE = 140173"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8untBwuIezVi"
      },
      "source": [
        "# datasets paths\r\n",
        "train_tfrecord_file_name = \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/SUBSET_2_train.tfrecord\"\r\n",
        "train_tfrecord_utkf_pt1_file_name =  \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/UTKFACE_train_pt1.tfrecord\"\r\n",
        "train_tfrecord_utkf_pt2_file_name = \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/UTKFACE_train_pt2.tfrecord\"\r\n",
        "train_tfrecord_appa_file_name = \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/APPA-REAL_train.tfrecord\"\r\n",
        "val_tfrecord_file_name = \"/content/gdrive/MyDrive/CONSEGNA/DATASETS/SUBSET_2_val.tfrecord\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOfKOPFwINLj"
      },
      "source": [
        "# RUN TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTztf5hcXOmD"
      },
      "source": [
        "## Ground truth labels dictionary creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKn66fastQP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565d1291-118f-4e8b-a8b2-ce295d595c44"
      },
      "source": [
        "# create labels dictionary for SUBSET_2\r\n",
        "\r\n",
        "from csv import reader\r\n",
        "\r\n",
        "labels_csv_filename = '/content/gdrive/MyDrive/CONSEGNA/DATASETS/train.age_detected.csv'\r\n",
        "\r\n",
        "def create_label_dictionary():\r\n",
        "    temp_dict = {}\r\n",
        "    with open(labels_csv_filename, 'r') as read_obj:\r\n",
        "        csv_reader = reader(read_obj)\r\n",
        "        for row in csv_reader:\r\n",
        "            age = str(row[-1])\r\n",
        "            temp_dict[row[0]] = age\r\n",
        "    return temp_dict\r\n",
        "\r\n",
        "labels_dictionary = create_label_dictionary()\r\n",
        "print(\"Labels obtained\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels obtained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBMcW8ABegbn"
      },
      "source": [
        "## DataAugmentation Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXWdtgskcyIt"
      },
      "source": [
        "from dataset_tools import get_random_eraser\r\n",
        "\r\n",
        "class CropoutAugmentation():\r\n",
        "    def __init__(self):\r\n",
        "        self.eraser = get_random_eraser()\r\n",
        "    def before_cut(self, img):\r\n",
        "        return img\r\n",
        "    def after_cut(self, img):\r\n",
        "        return self.eraser(img)\r\n",
        "\r\n",
        "class DefaultAugmentation():\r\n",
        "    def before_cut(self, frame, roi):\r\n",
        "        frame = random_image_rotate(frame, roi_center(roi))\r\n",
        "        frame = random_image_skew(frame, roi_center(roi))\r\n",
        "        return frame\r\n",
        "    def augment_roi(self, roi):\r\n",
        "        roi = random_change_roi(roi)\r\n",
        "        roi = enclosing_square(roi)\r\n",
        "        return roi\r\n",
        "        \r\n",
        "    def after_cut(self, img):\r\n",
        "        img = random_brightness_contrast(img)\r\n",
        "        img = random_flip(img)\r\n",
        "        return img\r\n",
        "\r\n",
        "class VGGFace2Augmentation():\r\n",
        "    def before_cut(self, frame, roi):\r\n",
        "        frame = random_monochrome(frame, random_fraction_yes=0.2)\r\n",
        "        return frame\r\n",
        "    def augment_roi(self, roi):\r\n",
        "        roi= add_margin(roi, 0.3)\r\n",
        "        roi = random_fixed_size_roi(roi, original_size=(256,256), dst_size=(224,224))\r\n",
        "        return roi\r\n",
        "    def after_cut(self, img):\r\n",
        "        img = random_flip(img)\r\n",
        "        return img\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "def get_random_crop(image, crop_height, crop_width):\r\n",
        "\r\n",
        "    max_x = image.shape[1] - crop_width\r\n",
        "    max_y = image.shape[0] - crop_height\r\n",
        "\r\n",
        "    x = np.random.randint(0, max_x)\r\n",
        "    y = np.random.randint(0, max_y)\r\n",
        "\r\n",
        "    crop = image[y: y + crop_height, x: x + crop_width]\r\n",
        "    \r\n",
        "    return crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh53SXOd8aHN"
      },
      "source": [
        "## Parse tfrecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fpSJQF4bcv1"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "def decode_image(image):\r\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\r\n",
        "    image = tf.image.resize(image, [240, 240])\r\n",
        "    image = tf.cast(image, tf.uint8)\r\n",
        "    return image\r\n",
        "\r\n",
        "def get_age_vggface2(filename):\r\n",
        "  return round(float(labels_dictionary[filename]))\r\n",
        "\r\n",
        "def get_age_utkf(filename):\r\n",
        "  return round(float(str(filename).split(\"_\",1)[0]))\r\n",
        "\r\n",
        "def get_age(filename):\r\n",
        "  filename = str(filename).split(\"'\",2)[1]\r\n",
        "  if str(filename).split(\".\")[-2] == \"chip\":\r\n",
        "    return get_age_utkf(filename)\r\n",
        "  else:\r\n",
        "    return get_age_vggface2(filename)\r\n",
        "\r\n",
        "def conv_normalize(image):\r\n",
        "  return keras_vggface.utils.preprocess_input(image, 'channels_last', version=2)\r\n",
        "\r\n",
        "def conv_BGR2RGB(image):\r\n",
        "  return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
        "\r\n",
        "def conv_RGB2BGR(image):\r\n",
        "  return cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
        "\r\n",
        "def apply_transform(image):\r\n",
        "\r\n",
        "  choice = random.getrandbits(1)\r\n",
        "  if choice == 1:\r\n",
        "    crp = CropoutAugmentation()\r\n",
        "    image = crp.after_cut(image)\r\n",
        "\r\n",
        "  choice = random.getrandbits(1)\r\n",
        "  if choice == 1:\r\n",
        "    image = dataset_tools.random_flip(image)\r\n",
        "\r\n",
        "  choice = random.getrandbits(1)\r\n",
        "  if choice == 1:\r\n",
        "    image = dataset_tools.random_brightness_contrast(image)\r\n",
        "\r\n",
        "  choice = random.getrandbits(1)\r\n",
        "  if choice == 1:\r\n",
        "    image = get_random_crop(image, 150, 150)\r\n",
        "    dim = (240, 240)\r\n",
        "    # resize image\r\n",
        "    image = cv2.resize(image, dim)\r\n",
        "  \r\n",
        "  image = tf.cast(image, tf.uint8)\r\n",
        "  return image\r\n",
        "\r\n",
        "def DataAugmentation(image):\r\n",
        "  choice = np.random.choice([True, False], size=1, replace=False, p=[0.30, 0.70])\r\n",
        "  if choice[0] == True:\r\n",
        "    return apply_transform(image)\r\n",
        "  else:\r\n",
        "    return image\r\n",
        "\r\n",
        "# parse tfrecord samples\r\n",
        "def read_tfrecord(example, labeled, train, ds_type):\r\n",
        "    features = (\r\n",
        "        {\r\n",
        "          \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\r\n",
        "          \"filename\": tf.io.FixedLenFeature([], dtype=tf.string),\r\n",
        "          \"label\": tf.io.FixedLenFeature([], dtype=tf.int64)\r\n",
        "        } if ds_type == \"appa\"\r\n",
        "        else{\r\n",
        "          \"image\": tf.io.FixedLenFeature([], dtype=tf.string),\r\n",
        "          \"filename\": tf.io.FixedLenFeature([], dtype=tf.string)  \r\n",
        "        }\r\n",
        "    )\r\n",
        "\r\n",
        "    example = tf.io.parse_single_example(example, features)\r\n",
        "\r\n",
        "    image = example[\"image\"]\r\n",
        "    \r\n",
        "    image = decode_image(image) # the decoded image has BGR channels\r\n",
        "    \r\n",
        "    # Apply data augmentation\r\n",
        "    if train:\r\n",
        "      image = tf.numpy_function(DataAugmentation, [image], tf.uint8)\r\n",
        "    \r\n",
        "    # Normalize the image (substract mean)\r\n",
        "    image = tf.numpy_function(conv_BGR2RGB, [image], tf.uint8)\r\n",
        "    image = tf.cast(image, dtype=tf.float32)\r\n",
        "\r\n",
        "    # conv_normalize needs RGB images as input and returns BGR images as output\r\n",
        "    image = tf.numpy_function(conv_normalize, [image], tf.float32)\r\n",
        "\r\n",
        "    filename = example[\"filename\"]\r\n",
        "\r\n",
        "    \r\n",
        "    if labeled:\r\n",
        "      if ds_type != \"appa\":\r\n",
        "        label = tf.numpy_function(get_age, [filename], tf.int64)\r\n",
        "      else:\r\n",
        "        label = example[\"label\"]\r\n",
        "      return image, label\r\n",
        "    return image "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doxWC4PKpfen"
      },
      "source": [
        "## Loading the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MaI0ozQpe7b"
      },
      "source": [
        "def load_dataset(tfrecord_filename, labeled=True, train = True, ds_type = \"vggface2\"):\r\n",
        "    ignore_order = tf.data.Options()\r\n",
        "    ignore_order.experimental_deterministic = False  # disable order, increase speed\r\n",
        "    dataset = tf.data.TFRecordDataset(\r\n",
        "        tfrecord_filename\r\n",
        "    )\r\n",
        "    \r\n",
        "    dataset = dataset.with_options(\r\n",
        "        ignore_order\r\n",
        "    )  # uses data as soon as it streams in, rather than in its original order\r\n",
        "    \r\n",
        "    dataset = dataset.map(\r\n",
        "        partial(read_tfrecord, labeled = labeled, train = train, ds_type = ds_type), num_parallel_calls=tf.data.experimental.AUTOTUNE\r\n",
        "    )\r\n",
        "    \r\n",
        "    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\r\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1_vjOkapa7h"
      },
      "source": [
        "## Pipeline creation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dVS5d5EuW3P"
      },
      "source": [
        "# Concatanates batches\r\n",
        "def concat(*ds_elements):\r\n",
        "    #Create one empty list for each component of the dataset\r\n",
        "    lists = [[] for _ in ds_elements[0]]\r\n",
        "    for element in ds_elements:\r\n",
        "        for i, tensor in enumerate(element):\r\n",
        "            #For each element, add all its component to the associated list\r\n",
        "            lists[i].append(tensor)\r\n",
        "    #Concatenate each component list\r\n",
        "    return tuple(tf.concat(l, axis=0) for l in lists)\r\n",
        "\r\n",
        "# Create a dataset pipeline composed by:\r\n",
        "#   - shuffling of data\r\n",
        "#   - creation of batches\r\n",
        "#   - prefatch of data to speed up the training\r\n",
        "def apply_pipeline(paths, labeled = True, train = True):\r\n",
        "\r\n",
        "    # Training set must be composed by data coming from VGGFace2, UTKFace and APPA-REAL datasets\r\n",
        "    # Every batch is composed by 52 images from VGGFACE2, 8 images coming from UTKFace and 4 images from APPA-REAL  \r\n",
        "    if train:\r\n",
        "      vf2_dataset = load_dataset(paths[0], train=train)\r\n",
        "      utkf_dataset1 = load_dataset(paths[1], train=train, ds_type=\"utkf\")\r\n",
        "      utkf_dataset2 = load_dataset(paths[2], train=train, ds_type=\"utkf\")\r\n",
        "      appa_dataset = load_dataset(paths[3], train=train, ds_type = \"appa\")\r\n",
        "      \r\n",
        "      zipped_ds = tf.data.Dataset.zip((vf2_dataset.shuffle(BATCH_SIZE*5).batch(52),\r\n",
        "                                      utkf_dataset1.shuffle(BATCH_SIZE).repeat().batch(4),\r\n",
        "                                      utkf_dataset2.shuffle(BATCH_SIZE).repeat().batch(4),\r\n",
        "                                      appa_dataset.shuffle(BATCH_SIZE).repeat().batch(4)))\r\n",
        "      unbalanced_batches_ds = zipped_ds.map(concat)\r\n",
        "      dataset = unbalanced_batches_ds.repeat()\r\n",
        "      dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "    \r\n",
        "    # Validation set is composed only by data coming from VGGFace2 dataset\r\n",
        "    else:\r\n",
        "      dataset = load_dataset(paths[0], labeled = labeled, train = train)\r\n",
        "      dataset = dataset.shuffle(BATCH_SIZE*5)\r\n",
        "      dataset = dataset.batch(BATCH_SIZE)\r\n",
        "      dataset = dataset.repeat()\r\n",
        "      dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgiZmxTLq5I1"
      },
      "source": [
        "## Fit callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSFhaJeBKW5o"
      },
      "source": [
        "# tensorboard callback\r\n",
        "class LRTensorBoard(TensorBoard):\r\n",
        "\r\n",
        "  def __init__(self, log_dir, **kwargs):\r\n",
        "    super().__init__(log_dir, **kwargs)\r\n",
        "    self.lr_writer = tf.summary.create_file_writer(self.log_dir + '/learning')\r\n",
        "\r\n",
        "  def on_epoch_end(self, epoch, logs=None):\r\n",
        "    lr = getattr(self.model.optimizer, 'lr', None)\r\n",
        "    with self.lr_writer.as_default():\r\n",
        "      summary = tf.summary.scalar('learning_rate', lr, epoch)\r\n",
        "\r\n",
        "    super().on_epoch_end(epoch, logs)\r\n",
        "\r\n",
        "  def on_train_end(self, logs=None):\r\n",
        "    super().on_train_end(logs)\r\n",
        "    self.lr_writer.close()\r\n",
        "\r\n",
        "tensorboard_callback = LRTensorBoard(log_dir=TENSOR_BOARD_PATH)\r\n",
        "\r\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    FOLDER_CHECKPOINT,\r\n",
        "    save_best_only=False,\r\n",
        "    verbose = 1,\r\n",
        "    save_freq = 'epoch',\r\n",
        "    monitor='val_loss',\r\n",
        "    mode = 'min'\r\n",
        ")\r\n",
        "\r\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor='val_loss', patience=5, min_delta = 0.01, verbose = 1, mode = 'min', restore_best_weights=True\r\n",
        ")\r\n",
        "\r\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\r\n",
        "    monitor='val_loss', factor=0.1, patience=3, min_delta = 0.1, mode = 'min', min_lr=0.0000001, verbose = 1\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkXHHTlLwex1"
      },
      "source": [
        "## Model creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwHQU6rVs0bg"
      },
      "source": [
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, LeakyReLU, PReLU\r\n",
        "from tensorflow.keras.initializers import Constant\r\n",
        "\r\n",
        "def create_dense(num_neurons, x):\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Dense(num_neurons)(x)\r\n",
        "    x = PReLU(alpha_initializer=Constant(value=0.6), alpha_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.01))(x)\r\n",
        "    x = Dropout(.2)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Dense(num_neurons)(x)\r\n",
        "    x = PReLU(alpha_initializer=Constant(value=0.6), alpha_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.01))(x)\r\n",
        "    x = Dropout(.2)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    predictions = Dense(1, activation='relu')(x)\r\n",
        "    return predictions\r\n",
        "\r\n",
        "def make_model():\r\n",
        "  \r\n",
        "  # creation of the base pre-trained model\r\n",
        "  base_model = VGGFace(include_top=False, input_shape=(240, 240, 3), pooling='avg', model=BASE_MODEL, weights = WEIGHTS)\r\n",
        "  x = base_model.output\r\n",
        "  last_layer = create_dense(2048, x)\r\n",
        "  model = Model(inputs=base_model.input, outputs=last_layer)\r\n",
        "  \r\n",
        "  # set the internal layers to be trainable\r\n",
        "  for layer in base_model.layers:\r\n",
        "      layer.trainable = True\r\n",
        "\r\n",
        "  # compile the model\r\n",
        "  model.compile(\r\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.9),\r\n",
        "      loss=tf.keras.losses.MeanAbsoluteError()\r\n",
        "  )\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAfMFPLBbDOQ"
      },
      "source": [
        "model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zoc4pPBUplNY"
      },
      "source": [
        "## FIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zDKfDR1eSpj"
      },
      "source": [
        "%tensorboard --logdir /content/gdrive/MyDrive/CONSEGNA/TRAIN/logs/scalars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-DpeVLMhdo-"
      },
      "source": [
        "# datasets pipeline creation\r\n",
        "train_dataset = apply_pipeline([train_tfrecord_file_name, train_tfrecord_utkf_pt1_file_name, train_tfrecord_utkf_pt2_file_name, train_tfrecord_appa_file_name], train = True)\r\n",
        "validation_dataset = apply_pipeline([val_tfrecord_file_name], train = False)\r\n",
        "\r\n",
        "# -------------------\r\n",
        "tf.config.run_functions_eagerly(True)\r\n",
        "\r\n",
        "history = model.fit(\r\n",
        "    train_dataset,\r\n",
        "    epochs=NUM_EPOCHS,\r\n",
        "    validation_data=validation_dataset,\r\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr, tensorboard_callback],\r\n",
        "    steps_per_epoch = TRAIN_SIZE/BATCH_SIZE,\r\n",
        "    verbose = 1,\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    validation_steps = VAL_SIZE/BATCH_SIZE\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}